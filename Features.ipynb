{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\"input/TrainQuestions.csv\", encoding='latin1')\n",
    "answers = pd.read_csv(\"input/TrainAnswers.csv\", encoding='latin1')\n",
    "tags = pd.read_csv(\"input/TrainTags.csv\", encoding='latin1')\n",
    "users = pd.read_csv(\"users.csv\", encoding='latin1')\n",
    "tag_features = pd.read_csv('tags_features.csv', encoding='latin1')\n",
    "tag_ids = set(tag_features['qnid'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('en_US.txt') as f:\n",
    "    en_dict = set(f.read().splitlines())\n",
    "with open('en_US2.txt') as f:\n",
    "    en_dict = en_dict.union(set(f.read().splitlines()))\n",
    "with open('programmingDict.txt') as f:\n",
    "    en_dict = en_dict.union(set(f.read().splitlines()))\n",
    "punctuation = set(['.',',',';',':','(',')','!','?','\\\"'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_code_links(soup):\n",
    "    link= soup.a\n",
    "    while link is not None:\n",
    "        link.replace_with(\"link\")\n",
    "        link = link.code\n",
    "\n",
    "    code = soup.code\n",
    "    while code is not None:\n",
    "        code.replace_with(\"code\")\n",
    "        code = soup.code\n",
    "        \n",
    "    return soup.getText()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_spell_errors(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    error_count = 0\n",
    "    for s in sentences:\n",
    "        if s[0].islower():\n",
    "            error_count += 1\n",
    "        r = ''.join([c for c in s if not c in punctuation])\n",
    "        words = r.split()\n",
    "        if words:\n",
    "            word = words[0]\n",
    "            if word not in en_dict and word.lower() not in en_dict:\n",
    "                #print(word)\n",
    "                error_count+=1\n",
    "            for w in words[1:]:\n",
    "                if w not in en_dict:\n",
    "                    #print(w)\n",
    "                    error_count+=1\n",
    "    return error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length_error(soup):\n",
    "    text = filter_code_links(soup)\n",
    "    error_ct = count_spell_errors(text)\n",
    "    length = len(text.split())\n",
    "    error_ratio = 0\n",
    "    if length > 0:\n",
    "        error_ratio = error_ct*1.0/length\n",
    "    return length, error_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature(data):\n",
    "    global users\n",
    "    feat = [1]\n",
    "    \n",
    "    #Getting Body related Features\n",
    "    soup = BeautifulSoup(data['Body'],\"lxml\")\n",
    "    numtags = len(set([tag.name for tag in soup.body.findAll(True)]))\n",
    "    isimage = 1 if soup.body.findAll(\"img\") else 0\n",
    "    islink = 1 if soup.body.findAll(\"a\") else 0\n",
    "    \n",
    "    code_length = 0\n",
    "    allCode = soup.body.findAll(\"code\")\n",
    "    if allCode:\n",
    "        iscode = 1\n",
    "        for code in allCode:\n",
    "            code_length += len(str(code).split())\n",
    "    else:\n",
    "        iscode = 0\n",
    "    soup_body = BeautifulSoup(data['Body'],\"lxml\")\n",
    "    body_length, error_ratio_body = get_length_error(soup_body)\n",
    "    feat.extend([numtags, isimage, islink, iscode, code_length, body_length, error_ratio_body])\n",
    "    \n",
    "    #Getting title features\n",
    "    soup_title = BeautifulSoup(data['Title'],\"lxml\")\n",
    "    title_length, error_ratio_title = get_length_error(soup_title)\n",
    "    feat.extend([title_length, error_ratio_title])\n",
    "    \n",
    "    #Getting Creation Date info\n",
    "    weekday = [0] * 7\n",
    "    time_of_day = [0] * 4\n",
    "    year = [0] * 9\n",
    "    creation_date = datetime.datetime.strptime(data['CreationDate'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    weekday[creation_date.weekday()] = 1\n",
    "    time_of_day[int(creation_date.hour/6)] = 1\n",
    "    try:\n",
    "        year[creation_date.year-2008] = 1\n",
    "    except Exception as e:\n",
    "        print (creation_date.year)\n",
    "    feat.extend(weekday)\n",
    "    feat.extend(time_of_day)\n",
    "    feat.extend(year)\n",
    "    \n",
    "    #Getting User related Features\n",
    "    badges = -1\n",
    "    reputation = -1\n",
    "    accept_rate = -1\n",
    "    if not np.isnan(data['OwnerUserId']) and int(data['OwnerUserId']) in users['User Id'].values:\n",
    "        ownerdata = users.loc[users['User Id']==int(data['OwnerUserId'])].iloc[0]\n",
    "        badges = ownerdata['Bronze Badges'] + ownerdata['Silver Badges'] + ownerdata['Gold Badges']\n",
    "        reputation = ownerdata['Reputation']\n",
    "        if not np.isnan(ownerdata['Accept Rate']):\n",
    "            accept_rate = ownerdata['Accept Rate']\n",
    "    feat.extend([badges, reputation, accept_rate])\n",
    "    \n",
    "    #Getting Tag Related Info\n",
    "    tags = [0] * 100\n",
    "    avg_populatrity = 0\n",
    "    max_popularity = 0\n",
    "    if data['Id'] in tag_ids:\n",
    "        tags = tag_features[tag_features['qnid']==data['Id']]['encoded_tags'].tolist()[0]\n",
    "        if tags.startswith('['):\n",
    "            tags = tags[1:]\n",
    "        if tags.endswith(']'):\n",
    "            tags = tags[:-1]\n",
    "        tags = (int(x) for x in tags.split(','))\n",
    "        avg_popularity = float(tag_features[tag_features['qnid']==data['Id']]['avg_popularity'])\n",
    "        max_popularity = float(tag_features[tag_features['qnid']==data['Id']]['max_popularity'])\n",
    "    feat.extend(tags)\n",
    "    feat.append(avg_popularity)\n",
    "    feat.append(max_popularity)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answerparentids = set(answers['ParentId'].tolist())\n",
    "def will_get_an_answer(data):\n",
    "    return 1 if data['Id'] in answerparentids else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_diff_for_first_answer(data):\n",
    "    if data['Id'] in answers['ParentId']:\n",
    "        str_creation_dates = answers[answers['ParentId']==data['Id']]['CreationDate']\n",
    "        min_answer_date = min([datetime.datetime.strptime(i, \"%Y-%m-%dT%H:%M:%SZ\") for i in str_creation_dates])\n",
    "        #print(str_creation_dates)\n",
    "        #print(min_answer_date)\n",
    "        question_date = datetime.datetime.strptime(data['CreationDate'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        #print(question_date)\n",
    "        if min_answer_date < question_date:\n",
    "            return (datetime.datetime.utcnow() - question_date).total_seconds()/3600\n",
    "        else:\n",
    "            return (min_answer_date - question_date).total_seconds()/3600\n",
    "        #print(time_diff.total_seconds())\n",
    "    else:\n",
    "        question_date = datetime.datetime.strptime(data['CreationDate'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        return (datetime.datetime.utcnow() - question_date).total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 0, 1, 12, 132, 0.07575757575757576, 7, 0.14285714285714285, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 36, 520, 83.0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0076523077401402205, 0.0274029567677647] 135\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "X = feature(questions.iloc[0])\n",
    "print(X,len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got features\n"
     ]
    }
   ],
   "source": [
    "#Will you get an answer\n",
    "X = [feature(questions.iloc[idx]) for idx in range(len(questions))]\n",
    "print(\"Got features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got labels\n"
     ]
    }
   ],
   "source": [
    "y = [will_get_an_answer(questions.iloc[idx]) for idx in range(len(questions))]\n",
    "print(\"Got labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has an answer: 87226 ,Doesnt have an answer: 12774\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:100000]\n",
    "y_train = y[:100000]\n",
    "X_val = X[100000:150000]\n",
    "y_val = y[100000:150000]\n",
    "X_test = X[150000:]\n",
    "y_test = y[150000:]\n",
    "print(\"Has an answer:\",sum(y_train),\",Doesnt have an answer:\",len(y_train)-sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier\n",
      "Validation Score: 0.86948\n",
      "F1 Validation Score: 0.930149419874\n"
     ]
    }
   ],
   "source": [
    "#Will you get an answer: Ada Boost Classifier\n",
    "abc = sklearn.ensemble.AdaBoostClassifier(n_estimators=700, learning_rate=0.05)\n",
    "print(\"Ada Boost Classifier\")\n",
    "abc.fit(X_train, y_train)\n",
    "#print(\"Train Score:\",gbc.train_score_)\n",
    "#Accuracy\n",
    "print(\"Validation Score:\",abc.score(X_val, y_val))\n",
    "pred_val = abc.predict(X_val)\n",
    "print(\"F1 Validation Score:\",sklearn.metrics.f1_score(y_val, pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features\n",
      "[ 0.          0.03        0.03571429  0.00285714  0.01        0.09142857\n",
      "  0.04285714  0.02285714  0.06571429  0.01857143  0.19857143  0.34571429\n",
      "  0.13571429]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Imporatance\")\n",
    "feature_names=['Number of tags in body','Is image present','Is URL present','Is Code present','Length of Code',\\\n",
    "              '# words in body','Spell check error ratio in body','# words in title','Spell check error ratio in title', \\\n",
    "              'One hot encoded weekday','One hot encoded hour of day','One hot encoded year','Asker Badges','Asker Reputation', 'Asker Accept Rate']\n",
    "print(abc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Validation Score: 0.99848\n",
      "F1 Validation Score: 0.775147928994\n"
     ]
    }
   ],
   "source": [
    "#Will you get an answer: Gradient Boosting Classifier\n",
    "params = {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 3,\n",
    "          'learning_rate': 0.1, 'loss': 'exponential'}\n",
    "print(\"Gradient Boosting Classifier\")\n",
    "gbc = sklearn.ensemble.GradientBoostingClassifier(**params)\n",
    "gbc.fit(X_train, y_train)\n",
    "#print(\"Train Score:\",gbc.train_score_)\n",
    "#Accuracy\n",
    "print(\"Validation Score:\",gbc.score(X_val, y_val))\n",
    "pred_val = gbc.predict(X_val)\n",
    "print(\"F1 Validation Score:\",sklearn.metrics.f1_score(y_val, pred_val))\n",
    "#Gradient Boosting Classifier\n",
    "#Validation Score: 0.9985\n",
    "#F1 Validation Score: 0.776119402985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 0.99728\n",
      "F1 Validation Score: 0.418803418803\n"
     ]
    }
   ],
   "source": [
    "# #Will you get an answer: SVM Classifier\n",
    "# print(\"SVM Linear Classifier\")\n",
    "# svmc = sklearn.svm.SVC(0.5, 'linear')\n",
    "# svmc.fit(X_train, y_train)\n",
    "# print(\"Validation Score:\",svmc.score(X_val, y_val))\n",
    "# pred_val = svmc.predict(X_val)\n",
    "# print(\"F1 Validation Score:\",sklearn.metrics.f1_score(y_val, pred_val))\n",
    "# #SVM Linear Classifier\n",
    "# #Validation Score: 0.99728\n",
    "# #F1 Validation Score: 0.418803418803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got labels\n"
     ]
    }
   ],
   "source": [
    "# #Time(seconds) after which you get the first answer\n",
    "# y = [time_diff_for_first_answer(questions.iloc[idx]) for idx in range(len(questions))]\n",
    "# print(\"Got labels\")\n",
    "# y_train = y[:100000]\n",
    "# y_val = y[100000:150000]\n",
    "# y_test = y[150000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor\n",
      "Validation Score: 0.959619858873\n",
      "MSE Validation: 1.48939631588e+14\n",
      "MAE Validation: 7901060.68541\n"
     ]
    }
   ],
   "source": [
    "# #Time(seconds) after which you get the first answer: Gradient Boosting Regressor\n",
    "# params = {'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 3,\n",
    "#           'learning_rate': 0.05, 'loss': 'ls'}\n",
    "# print(\"Gradient Boosting Regressor\")\n",
    "# gbr = sklearn.ensemble.GradientBoostingRegressor(**params)\n",
    "# gbr.fit(X_train, y_train)\n",
    "\n",
    "# #R^2 score\n",
    "# print(\"Validation Score:\",gbr.score(X_val, y_val))\n",
    "# pred_val = gbr.predict(X_val)\n",
    "# print(\"MSE Validation:\",sklearn.metrics.mean_squared_error(y_val, pred_val))\n",
    "# print(\"MAE Validation:\",sklearn.metrics.mean_absolute_error(y_val, pred_val))\n",
    "\n",
    "# #Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
